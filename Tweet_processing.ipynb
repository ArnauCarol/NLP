{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgtGdNOkEPZ1"
      },
      "source": [
        "#1 - Tubería"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12-UzAlMP03u"
      },
      "source": [
        "##1.0 - Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyJoyUXY3D3B",
        "outputId": "dabf9d0b-650b-4654-91d4-74ef44287c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji_extractor\n",
            "  Downloading emoji_extractor-1.0.20.tar.gz (34 kB)\n",
            "Building wheels for collected packages: emoji-extractor\n",
            "  Building wheel for emoji-extractor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji-extractor: filename=emoji_extractor-1.0.20-py3-none-any.whl size=63580 sha256=9c06918564708cd73d7c534ca7a7fa967c7e00a477ce4d2eeae4d1d748f03d4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/3a/10/4d60270bd4c7b1569ee392d611fbcbefc2af7d7245163913e3\n",
            "Successfully built emoji-extractor\n",
            "Installing collected packages: emoji-extractor\n",
            "Successfully installed emoji-extractor-1.0.20\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting ftfy<7.0,>=6.0\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=8467dd4372a82473882116eca8d8bda62ae064f7a7996314170cee923e94824e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: ftfy, emoji, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n",
            "--2022-09-06 21:40:57--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409871727 (391M) [application/x-gzip]\n",
            "Saving to: ‘pytorch_weights.tar.gz’\n",
            "\n",
            "pytorch_weights.tar 100%[===================>] 390.88M  8.25MB/s    in 50s     \n",
            "\n",
            "2022-09-06 21:41:48 (7.81 MB/s) - ‘pytorch_weights.tar.gz’ saved [409871727/409871727]\n",
            "\n",
            "--2022-09-06 21:41:49--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 242120 (236K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 236.45K   403KB/s    in 0.6s    \n",
            "\n",
            "2022-09-06 21:41:50 (403 KB/s) - ‘vocab.txt’ saved [242120/242120]\n",
            "\n",
            "--2022-09-06 21:41:50--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 313 [application/json]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]     313  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-06 21:41:51 (48.9 MB/s) - ‘config.json’ saved [313/313]\n",
            "\n",
            "pytorch/\n",
            "pytorch/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import os\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import re\n",
        "import datetime as dt\n",
        "# Instalación de la API\n",
        "#!pip install git+https://github.com/tweepy/tweepy.git\n",
        "#import tweepy\n",
        "from tqdm import tqdm\n",
        "!pip install emoji_extractor\n",
        "from emoji_extractor.extract import Extractor\n",
        "!pip install clean-text\n",
        "from cleantext import clean\n",
        "!pip install transformers\n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
        "!tar -xzvf pytorch_weights.tar.gz\n",
        "!mv config.json pytorch/.\n",
        "!mv vocab.txt pytorch/.\n",
        "##import torch\n",
        "from transformers import BertForMaskedLM, BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z34TO-O1FeJH"
      },
      "source": [
        "##1.3 - Tweets\n",
        "Descarga de las publicaciones (parte de la extracción) y transformación.\n",
        "\n",
        "Generación del marco de datos o dataset. Se incluyen los siguientes campos: nombre, usuario, ubicación (si lo tiene), descripción del usuario, verificación de la cuenta, fecha, texto, hashtags, y fuente (dispositivo) del tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nZo59YrSZFZs",
        "outputId": "51e7ba88-0bcb-48f6-8828-8d3181ecae33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b10efac3-c652-427c-a2ff-e83146e27d8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VALORACIONES</th>\n",
              "      <th>Valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accentos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mayusculas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sign_punt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>emojis</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abrev</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>extranjerismos</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>repet_termin</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>beto</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b10efac3-c652-427c-a2ff-e83146e27d8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b10efac3-c652-427c-a2ff-e83146e27d8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b10efac3-c652-427c-a2ff-e83146e27d8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     VALORACIONES  Valor\n",
              "0        accentos      1\n",
              "1      mayusculas      1\n",
              "2       sign_punt      1\n",
              "3          emojis     -1\n",
              "4           abrev     -1\n",
              "5  extranjerismos     -1\n",
              "6    repet_termin     -1\n",
              "7            beto      0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_val = {'accentos':1, 'mayusculas':1, 'sign_punt':1, 'emojis':-1, 'abrev':-1, 'extranjerismos': -1, 'repet_termin':-1, 'beto':0 }\n",
        "df_val = pd.DataFrame([[key, dict_val[key]] for key in dict_val.keys()], columns=['VALORACIONES', 'Valor'])\n",
        "df_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq4VzYma_gYj"
      },
      "source": [
        "---\n",
        "# 2 - Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFNVeYX212l7"
      },
      "source": [
        "### 2.1 - Preprocesado\n",
        "Eliminación de las palabras sin sentido o *stop words* y agrupación de emojis al final de la cadena.\n",
        "\n",
        "**¡OJO! Aquellas que contengan acentos o estén mal escritas, se quedarán.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VjbfmqGDUERm",
        "outputId": "38e3d9ec-df7a-4b13-8758-9f84db5fbacf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da80ab09-1db2-4f39-b22a-bc690a6d0b70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NA_1</td>\n",
              "      <td>Esta prueba consiste en quedarnos únicamente c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NA_2</td>\n",
              "      <td>En un lugar de la Mancha, de cuyo nombre no qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NA_3</td>\n",
              "      <td>Árbol de la familia de las ebenáceas, de diez ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NA_4</td>\n",
              "      <td>Mi tío tiene un apartamento con mucha luz y po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NA_5</td>\n",
              "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NA_6</td>\n",
              "      <td>Juego de mesa entre dos personas que se practi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NA_7</td>\n",
              "      <td>Red informática mundial, descentralizada, form...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NA_8</td>\n",
              "      <td>Instrumento astronómico usado antiguamente par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NA_9</td>\n",
              "      <td>Cuando los días pasan y las horas transcurren ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NA_10</td>\n",
              "      <td>Arbusto cultivado originario de Asia, de la fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NB_1</td>\n",
              "      <td>coger el resto... Prueba, lol . Pedro, nadies ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NB_2</td>\n",
              "      <td>Es una obra de arte porque el arte es asi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NB_3</td>\n",
              "      <td>La prueba ya con más cositas como 😍😍😺😺👏👏👏. \\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NB_4</td>\n",
              "      <td>tkm, estao ha de salir mal sino no sirve 😍😍😍.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NB_5</td>\n",
              "      <td>El arbol tene frutas buenas😺, plz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NB_6</td>\n",
              "      <td>mi amiga se fue corriendo a su casa para la in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NB_7</td>\n",
              "      <td>Estoy empezando a estudiar Francés rt, omg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NB_8</td>\n",
              "      <td>Las nuevas generaciones crecen muy rapido, tan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NB_9</td>\n",
              "      <td>la casa de mis padres es grande y tiene una pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NB_10</td>\n",
              "      <td>Los anacardos de volor verde aun no estan list...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da80ab09-1db2-4f39-b22a-bc690a6d0b70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da80ab09-1db2-4f39-b22a-bc690a6d0b70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da80ab09-1db2-4f39-b22a-bc690a6d0b70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     name                                               text\n",
              "0    NA_1  Esta prueba consiste en quedarnos únicamente c...\n",
              "1    NA_2  En un lugar de la Mancha, de cuyo nombre no qu...\n",
              "2    NA_3  Árbol de la familia de las ebenáceas, de diez ...\n",
              "3    NA_4  Mi tío tiene un apartamento con mucha luz y po...\n",
              "4    NA_5  El resto della concluían sayo de velarte, calz...\n",
              "5    NA_6  Juego de mesa entre dos personas que se practi...\n",
              "6    NA_7  Red informática mundial, descentralizada, form...\n",
              "7    NA_8  Instrumento astronómico usado antiguamente par...\n",
              "8    NA_9  Cuando los días pasan y las horas transcurren ...\n",
              "9   NA_10  Arbusto cultivado originario de Asia, de la fa...\n",
              "10   NB_1  coger el resto... Prueba, lol . Pedro, nadies ...\n",
              "11   NB_2          Es una obra de arte porque el arte es asi\n",
              "12   NB_3  La prueba ya con más cositas como 😍😍😺😺👏👏👏. \\n ...\n",
              "13   NB_4      tkm, estao ha de salir mal sino no sirve 😍😍😍.\n",
              "14   NB_5                  El arbol tene frutas buenas😺, plz\n",
              "15   NB_6  mi amiga se fue corriendo a su casa para la in...\n",
              "16   NB_7         Estoy empezando a estudiar Francés rt, omg\n",
              "17   NB_8  Las nuevas generaciones crecen muy rapido, tan...\n",
              "18   NB_9  la casa de mis padres es grande y tiene una pi...\n",
              "19  NB_10  Los anacardos de volor verde aun no estan list..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Textos de prueba\n",
        "NA_1 = \"Esta prueba consiste en quedarnos únicamente con las palabras y eliminar aquellas sin significado. \"\n",
        "NA_2 = 'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. '\n",
        "NA_3 = 'Árbol de la familia de las ebenáceas, de diez a doce metros de altura y de copa ancha.'\n",
        "NA_4 = 'Mi tío tiene un apartamento con mucha luz y por la ventana se puede ver el mar.'\n",
        "NA_5 = 'El resto della concluían sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los días de entresemana se honraba con su vellorí de lo más fino. Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.'\n",
        "NA_6 = 'Juego de mesa entre dos personas que se practica sobre un damero en el que se disponen las 16 piezas de cada jugador, desiguales en importancia y valor, que se desplazan y comen las del contrario según ciertas reglas.'\n",
        "NA_7 = 'Red informática mundial, descentralizada, formada por la conexión directa entre computadoras mediante un protocolo especial de comunicación.'\n",
        "NA_8 = 'Instrumento astronómico usado antiguamente para determinar la posición de los astros.'\n",
        "NA_9 = 'Cuando los días pasan y las horas transcurren te das cuenta de que la soledad no es una buena amiga.'\n",
        "NA_10 = 'Arbusto cultivado originario de Asia, de la familia de las rutáceas, de unos dos metros de altura, ramoso, con hojas casi persistentes, opuestas, aovadas, lisas y lustrosas, flores pequeñas en racimo, blancas y olorosas y por frutos bayas rojas, redondas y del tamaño de un guisante 😺 .'\n",
        "\n",
        "# Textos de prueba\n",
        "NB_1 = \"coger el resto... Prueba, lol . Pedro, nadies hindu tkm \"\n",
        "NB_2 = 'Es una obra de arte porque el arte es asi'\n",
        "NB_3 = 'La prueba ya con más cositas como 😍😍😺😺👏👏👏. \\n A ver si funciona 😍😍😺😺, LOL'\n",
        "NB_4 = 'tkm, estao ha de salir mal sino no sirve 😍😍😍.'\n",
        "NB_5 = 'El arbol tene frutas buenas😺, plz'\n",
        "NB_6 = 'mi amiga se fue corriendo a su casa para la inaguración'\n",
        "NB_7 = 'Estoy empezando a estudiar Francés rt, omg'\n",
        "NB_8 = 'Las nuevas generaciones crecen muy rapido, tan rapido como nosotros.'\n",
        "NB_9 = 'la casa de mis padres es grande y tiene una picina que comprastes'\n",
        "NB_10 = 'Los anacardos de volor verde aun no estan listos para ser recogidos'\n",
        "\n",
        "\n",
        "\n",
        "# Creación del DataFrame para probar, no será necesario porque vendrá de la tubería\n",
        "dicc = {'name': ['NA_1', 'NA_2', 'NA_3', 'NA_4', 'NA_5', 'NA_6', 'NA_7', 'NA_8', 'NA_9', 'NA_10', 'NB_1', 'NB_2', 'NB_3', 'NB_4', 'NB_5', 'NB_6', 'NB_7', 'NB_8', 'NB_9', 'NB_10'], \n",
        "        'text': [NA_1, NA_2, NA_3, NA_4, NA_5, NA_6, NA_7, NA_8, NA_9, NA_10, NB_1, NB_2, NB_3, NB_4, NB_5, NB_6, NB_7, NB_8, NB_9, NB_10]}\n",
        "df_demo = pd.DataFrame(dicc)\n",
        "df_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wD3TGDUaHdWv",
        "outputId": "06ab7a65-c168-411c-ead8-6263449b09fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# Diccionario español\n",
        "stops = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sW9Cq2CKgccT",
        "outputId": "e7a3590b-613e-4182-af79-bae4815e1426"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd668fc5-244e-4e39-bed2-5002f503880b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NA_1</td>\n",
              "      <td>Esta prueba consiste en quedarnos únicamente c...</td>\n",
              "      <td>Esta prueba consiste en quedarnos únicamente c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NA_2</td>\n",
              "      <td>En un lugar de la Mancha, de cuyo nombre no qu...</td>\n",
              "      <td>En un lugar de la Mancha, de cuyo nombre no qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NA_3</td>\n",
              "      <td>Árbol de la familia de las ebenáceas, de diez ...</td>\n",
              "      <td>Árbol de la familia de las ebenáceas, de diez ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NA_4</td>\n",
              "      <td>Mi tío tiene un apartamento con mucha luz y po...</td>\n",
              "      <td>Mi tío tiene un apartamento con mucha luz y po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NA_5</td>\n",
              "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
              "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NA_6</td>\n",
              "      <td>Juego de mesa entre dos personas que se practi...</td>\n",
              "      <td>Juego de mesa entre dos personas que se practi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NA_7</td>\n",
              "      <td>Red informática mundial, descentralizada, form...</td>\n",
              "      <td>Red informática mundial, descentralizada, form...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NA_8</td>\n",
              "      <td>Instrumento astronómico usado antiguamente par...</td>\n",
              "      <td>Instrumento astronómico usado antiguamente par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NA_9</td>\n",
              "      <td>Cuando los días pasan y las horas transcurren ...</td>\n",
              "      <td>Cuando los días pasan y las horas transcurren ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NA_10</td>\n",
              "      <td>Arbusto cultivado originario de Asia, de la fa...</td>\n",
              "      <td>Arbusto cultivado originario de Asia, de la fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NB_1</td>\n",
              "      <td>coger el resto... Prueba, lol . Pedro, nadies ...</td>\n",
              "      <td>coger el resto... Prueba, lol . Pedro, nadies ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NB_2</td>\n",
              "      <td>Es una obra de arte porque el arte es asi</td>\n",
              "      <td>Es una obra de arte porque el arte es asi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NB_3</td>\n",
              "      <td>La prueba ya con más cositas como 😍😍😺😺👏👏👏. \\n ...</td>\n",
              "      <td>La prueba ya con más cositas como . A ver si f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NB_4</td>\n",
              "      <td>tkm, estao ha de salir mal sino no sirve 😍😍😍.</td>\n",
              "      <td>tkm, estao ha de salir mal sino no sirve . 😍</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NB_5</td>\n",
              "      <td>El arbol tene frutas buenas😺, plz</td>\n",
              "      <td>El arbol tene frutas buenas, plz 😺</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NB_6</td>\n",
              "      <td>mi amiga se fue corriendo a su casa para la in...</td>\n",
              "      <td>mi amiga se fue corriendo a su casa para la in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NB_7</td>\n",
              "      <td>Estoy empezando a estudiar Francés rt, omg</td>\n",
              "      <td>Estoy empezando a estudiar Francés rt, omg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NB_8</td>\n",
              "      <td>Las nuevas generaciones crecen muy rapido, tan...</td>\n",
              "      <td>Las nuevas generaciones crecen muy rapido, tan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NB_9</td>\n",
              "      <td>la casa de mis padres es grande y tiene una pi...</td>\n",
              "      <td>la casa de mis padres es grande y tiene una pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NB_10</td>\n",
              "      <td>Los anacardos de volor verde aun no estan list...</td>\n",
              "      <td>Los anacardos de volor verde aun no estan list...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd668fc5-244e-4e39-bed2-5002f503880b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd668fc5-244e-4e39-bed2-5002f503880b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd668fc5-244e-4e39-bed2-5002f503880b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     name                                               text  \\\n",
              "0    NA_1  Esta prueba consiste en quedarnos únicamente c...   \n",
              "1    NA_2  En un lugar de la Mancha, de cuyo nombre no qu...   \n",
              "2    NA_3  Árbol de la familia de las ebenáceas, de diez ...   \n",
              "3    NA_4  Mi tío tiene un apartamento con mucha luz y po...   \n",
              "4    NA_5  El resto della concluían sayo de velarte, calz...   \n",
              "5    NA_6  Juego de mesa entre dos personas que se practi...   \n",
              "6    NA_7  Red informática mundial, descentralizada, form...   \n",
              "7    NA_8  Instrumento astronómico usado antiguamente par...   \n",
              "8    NA_9  Cuando los días pasan y las horas transcurren ...   \n",
              "9   NA_10  Arbusto cultivado originario de Asia, de la fa...   \n",
              "10   NB_1  coger el resto... Prueba, lol . Pedro, nadies ...   \n",
              "11   NB_2          Es una obra de arte porque el arte es asi   \n",
              "12   NB_3  La prueba ya con más cositas como 😍😍😺😺👏👏👏. \\n ...   \n",
              "13   NB_4      tkm, estao ha de salir mal sino no sirve 😍😍😍.   \n",
              "14   NB_5                  El arbol tene frutas buenas😺, plz   \n",
              "15   NB_6  mi amiga se fue corriendo a su casa para la in...   \n",
              "16   NB_7         Estoy empezando a estudiar Francés rt, omg   \n",
              "17   NB_8  Las nuevas generaciones crecen muy rapido, tan...   \n",
              "18   NB_9  la casa de mis padres es grande y tiene una pi...   \n",
              "19  NB_10  Los anacardos de volor verde aun no estan list...   \n",
              "\n",
              "                                           text_clean  \n",
              "0   Esta prueba consiste en quedarnos únicamente c...  \n",
              "1   En un lugar de la Mancha, de cuyo nombre no qu...  \n",
              "2   Árbol de la familia de las ebenáceas, de diez ...  \n",
              "3   Mi tío tiene un apartamento con mucha luz y po...  \n",
              "4   El resto della concluían sayo de velarte, calz...  \n",
              "5   Juego de mesa entre dos personas que se practi...  \n",
              "6   Red informática mundial, descentralizada, form...  \n",
              "7   Instrumento astronómico usado antiguamente par...  \n",
              "8   Cuando los días pasan y las horas transcurren ...  \n",
              "9   Arbusto cultivado originario de Asia, de la fa...  \n",
              "10  coger el resto... Prueba, lol . Pedro, nadies ...  \n",
              "11         Es una obra de arte porque el arte es asi   \n",
              "12  La prueba ya con más cositas como . A ver si f...  \n",
              "13       tkm, estao ha de salir mal sino no sirve . 😍  \n",
              "14                 El arbol tene frutas buenas, plz 😺  \n",
              "15  mi amiga se fue corriendo a su casa para la in...  \n",
              "16        Estoy empezando a estudiar Francés rt, omg   \n",
              "17  Las nuevas generaciones crecen muy rapido, tan...  \n",
              "18  la casa de mis padres es grande y tiene una pi...  \n",
              "19  Los anacardos de volor verde aun no estan list...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Limpieza de datos\n",
        "# Movemos emojis al final y removemos espacios de más\n",
        "def clean_df(df):\n",
        "\n",
        "  extract = Extractor()\n",
        "  aux = df['text'].apply(lambda x: \" \".join(extract.count_emoji(x).keys() ))\n",
        "  aux2 = df['text'].apply(lambda x: clean( x, \n",
        "                                              lower=False,no_emoji=True,\n",
        "                                              no_line_breaks=True,\n",
        "                                              fix_unicode=False,\n",
        "                                              to_ascii=False\n",
        "                                          )\n",
        "                )\n",
        "  aux = aux2+\" \"+aux\n",
        "\n",
        "  df['text_clean'] = aux\n",
        "  return df\n",
        "\n",
        "df_demo = clean_df(df_demo)\n",
        "df_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7y935fOXHDUk"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords_(tweet):\n",
        "  df_demo['stop_words'] = df_demo['text_clean']\\\n",
        "                        .apply(lambda x: ' '.join([word for word in x.split() if word not in (stops)]))\n",
        "  return(df_demo)\n",
        "\n",
        "df_demo = remove_stopwords_(df_demo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hRaekqY9eFb"
      },
      "source": [
        "## 2.2 - Valoraciones\n",
        "Cada una de las próximas iteraciones representa una columna con una puntuación por cada usuario o fila. \n",
        "\n",
        "El sentido funcional de las valoraciones está basado de forma relativa, es decir, una proporción (modelo no supervisado). \n",
        "\n",
        "El sentido operacional es similar al de un modelo de one-hot, donde finalmente, una fila sumará la puntuación obtenida en cada columna o iteración.\n",
        "\n",
        "El resultado será una agrupación por puntuaciones obtenidas, pudiéndose agrupar tanto a nivel vertical como horizontal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_1eDed94wr"
      },
      "source": [
        "### 2.2.1 - Mayúsculas\n",
        "Numerador: nº de mayúsculas.\n",
        "\n",
        "Denominador: nº de palabras (sin stop_words, igual para el resto)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_o5ccTsWA8BA"
      },
      "outputs": [],
      "source": [
        "def get_capital_letters_(tweet):\n",
        "\tresult = re.findall(r'[A-Z]',tweet)\n",
        "\tstring = \"\".join(result)\n",
        "\treturn list(string)\n",
        "# Nueva columna pasando la función por cada una de las filas\t\n",
        "df_demo['capital_letters'] = df_demo['stop_words'].apply(lambda x : len(get_capital_letters_(x))/len(x.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5McOHwG_rvu"
      },
      "source": [
        "### 2.2.2 - Acentos\n",
        "Numerador: nº de palabras con acentos.\n",
        "\n",
        "Denominador: nº de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pEqqkqpE08Po"
      },
      "outputs": [],
      "source": [
        "def find_accent_words(tweet):\n",
        "  acentos = [\"áéíóúüÁÉÍÓÚÜ\"]\n",
        "  words = np.array([])\n",
        "  for pat in acentos[0]:\n",
        "    aux = \"\\w*[\"+pat+\"]\\w*\"\n",
        "    aux = re.findall(aux, tweet)\n",
        "    if len(aux) > 0:\n",
        "      words = np.append(words, aux)\n",
        "  return(len(words)/len(tweet.split()))\n",
        "\n",
        "df_demo['accents'] = df_demo['stop_words'].apply(lambda x: find_accent_words(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb1jtFnXvh3"
      },
      "source": [
        "### 2.2.3 - Signos de Puntuación\n",
        "Numerador: nº de signos.\n",
        "\n",
        "Denominador: nº de caracteres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BIUBWMpIPF2M"
      },
      "outputs": [],
      "source": [
        "def get_punctuations_marks_(tweet):\n",
        "\tresult = re.findall(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*',\n",
        "\t\t\t\t\t\ttweet)\n",
        "\tstring = \"\".join(result)\n",
        "\treturn list(string)\n",
        "# Nueva columna pasando la función por cada una de las filas\t\n",
        "df_demo['punctuation_marks'] = df_demo['stop_words'].apply(lambda x : len(get_punctuations_marks_(x))/len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlIu8PFjh_2z"
      },
      "source": [
        "### 2.2.4 - Longitud de Palabra\n",
        "Numerador: suma de los caracteres de todas las palabras.\n",
        "\n",
        "Denominador: nº de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e_sYw3AhCveu"
      },
      "outputs": [],
      "source": [
        "# Longitud de cada palabra -> String de números\n",
        "def word_length(tweet):\n",
        "  aux = [len(x) for x in tweet.split()]\n",
        "  return aux\n",
        "\n",
        "# Suma de los números de cada string para luego relativizarlo entre el número de palabras\n",
        "def sum_numbers(numbers):\n",
        "     if len(numbers) == 0:\n",
        "         return 0\n",
        "     return numbers[0] + sum_numbers(numbers[1:])\n",
        "\n",
        "df_demo['word_length'] = df_demo['stop_words'].apply(lambda x: sum_numbers(word_length(x))/len(x.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTAx-jI2BrNK"
      },
      "source": [
        "### 2.2.5 - Emojis\n",
        "Numerador: n° de emojis únicos.\n",
        "\n",
        "Denominador: n° de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LeQy1Bdqh-hI"
      },
      "outputs": [],
      "source": [
        "def detect_emoji(tweet):\n",
        "  extract = Extractor()\n",
        "  return len(extract.count_emoji(tweet).keys())/len(tweet.split())\n",
        "\n",
        "df_demo['emoji'] = df_demo['stop_words'].apply(lambda x: detect_emoji(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIVF4OuyBzRi"
      },
      "source": [
        "### 2.2.6 - Abreviaciones\n",
        "Numerador: nº de abreviaciones.\n",
        "\n",
        "Denominador: nº de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FhkL40o_6V06"
      },
      "outputs": [],
      "source": [
        "def get_abbreviation_(tweet):\n",
        "  abbr = ['rofl','pa','rl','lol','ptm','tqm','tkm','bb',\n",
        "         'fb','gpi','yt','tl','pls','oc','wtf','bc','bfn',\n",
        "         'dm','ftf','icymi','imho','irl','lmlt','np','oh',\n",
        "         'plz','qotd','rt','prt','rtrl','tmi','ty','tt','tl',\n",
        "         'cc','fa','fyi','+1','afk','brb','gtg','ht','hth', 'imo','lmao']\n",
        "  words = np.array([])\n",
        "  for pat in abbr[:]:\n",
        "    aux = \" \"+pat+\" \"\n",
        "    aux = re.findall(aux, tweet)\n",
        "    if len(aux) > 0:\n",
        "      words = np.append(words, aux)\n",
        "  return (len(words)/len(tweet.split()))\n",
        "  \n",
        "df_demo['abbreviation'] = df_demo['stop_words'].apply(lambda x: get_abbreviation_(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwRkfxyJCGwi"
      },
      "source": [
        "### 2.2.7 - Barbarismos\n",
        "Numerador: nº de extranjerismos.\n",
        "\n",
        "Denominador: nº de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Od-tOHUQRrqm"
      },
      "outputs": [],
      "source": [
        "def get_barbarism_(tweet):\n",
        "  barbar = ['comprastes','guevo','inaguración','nadies','picsa','custión',\n",
        "          'interperie','fuistes','ambos dos','jrito','hebreo','vertir',\n",
        "          'hindú','trompezar','adición','exepto','lego','líbido','hubiero',\n",
        "          'idiosincracia','beneficiencia','visicitud','suscinto','aférrimo',\n",
        "          'excéptico','convalescencia','discrección','esplanada','innundación',\n",
        "          'fideligno','fregaplatos','inexcrutable','misógeno','prevadicación',\n",
        "          'subrealista','sujección','transtornado','exalar','exhuberante',\n",
        "          'exumar','exausto','exibir']\n",
        "  words = np.array([])\n",
        "  for pat in barbar[:]:\n",
        "    aux = \"\\w*\"+pat+\"\\w*\"\n",
        "    aux = re.findall(aux, tweet)\n",
        "    if len(aux) > 0:\n",
        "      words = np.append(words, aux)\n",
        "  return (len(words)/len(tweet.split()))\n",
        "  \n",
        "df_demo['barbarism'] = df_demo['stop_words'].apply(lambda x: get_barbarism_(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_8ubRKYCRRe"
      },
      "source": [
        "### 2.2.8 - Repetición de Términos\n",
        "Numerador: n° de palabras únicas.\n",
        "\n",
        "Denominador: n° de palabras totales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nTg-k3m0J3oT"
      },
      "outputs": [],
      "source": [
        "def repeated_words(tweet):\n",
        "  aux = tweet.split()\n",
        "  aux_unique = np.unique(aux)\n",
        "  return(1 - len(aux_unique)/len(aux))\n",
        "  \n",
        "df_demo['repeticion'] = df_demo['stop_words'].apply(lambda x: repeated_words(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS9yM7N8CbiC"
      },
      "source": [
        "### 2.2.9 - BETO\n",
        "*Comparación con respuestas del BETO*.\n",
        "\n",
        "Numerador: N° de palabras coincidentes con las primeras 10 propuestas del BETO.\n",
        "\n",
        "Denominador: N° de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "shyD_g9opfPg",
        "outputId": "397dadc8-9c59-4e1e-c935-aa88b1c95676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a32a6f208454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# beto_pred(\"¿hola como estas? Espero no del todo mal. Aún no recibo la postal. Que prometiste el día en que te fuiste.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf_demo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BETO'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_demo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeto_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a32a6f208454>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# beto_pred(\"¿hola como estas? Espero no del todo mal. Aún no recibo la postal. Que prometiste el día en que te fuiste.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf_demo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BETO'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_demo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeto_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-a32a6f208454>\u001b[0m in \u001b[0;36mbeto_pred\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mindexed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtokens_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexed_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Predicción del Tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "def beto_pred(tweet):\n",
        "  split_tweet = re.findall(r\"[\\w']+|[.,¡!¿?;:]\", tweet)\n",
        "  c = 0\n",
        "\n",
        "  \n",
        "  for i in range(len(split_tweet)):\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False)\n",
        "    model = BertForMaskedLM.from_pretrained(\"pytorch/\")\n",
        "    e = model.eval()\n",
        "    # Ciclo por cada palabra o signo de interrogación del tweet\n",
        "    text = split_tweet.copy()\n",
        "    # Copia de la palabra a buscar.\n",
        "    real_word = text[i]\n",
        "    # Enmascarado de la palabra a buscar\n",
        "    text[i] = \"[MASK]\"\n",
        "    text = \"[CLS] \"+\" \".join(text)+\" [SEP]\"\n",
        "    \n",
        "    # Tokenización del Tweet\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # Predicción del Tweet\n",
        "    predictions = model(tokens_tensor)[0]\n",
        "\n",
        "    idxs = torch.argsort(predictions[0, i+1], descending=True)\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:2])\n",
        "\n",
        "    # print(text)\n",
        "    # print(predicted_token)\n",
        "    c = c + (real_word in predicted_token)\n",
        "  return c/len(split_tweet)\n",
        "    \n",
        "\n",
        "# beto_pred(\"¿hola como estas? Espero no del todo mal. Aún no recibo la postal. Que prometiste el día en que te fuiste.\")\n",
        "\n",
        "df_demo['BETO'] = df_demo['text_clean'].apply(lambda x: beto_pred(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4-FZ6KsMbQPE"
      },
      "outputs": [],
      "source": [
        "df_demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm6fuQUjAMMa"
      },
      "source": [
        "---\n",
        "## 2.3 - Segmentación / Clustering\n",
        "Agrupación de las valoraciones por segmentos o clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n5b6OXB0APxa"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jMyYQWeM8wW8"
      },
      "outputs": [],
      "source": [
        "df_val = df_demo.iloc[:,4:] # Selecionar filas de valoraciones\n",
        "array_val = df_val.to_numpy()# Convertir a array\n",
        "scaler = StandardScaler()#Escalamos los valores de l'array\n",
        "scaled_val = scaler.fit_transform(array_val)\n",
        "df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uk6gXDCpBeqR"
      },
      "outputs": [],
      "source": [
        "# K-means con 2 clusters(mayor/menot nivel de educación)\n",
        "kmeans = KMeans(\n",
        "  init=\"random\",\n",
        "  n_clusters=2,\n",
        "  n_init=10,\n",
        "  max_iter=300,\n",
        "  random_state=42\n",
        ")\n",
        "\n",
        "kmeans.fit(scaled_val)\n",
        "\n",
        "# Categoria de cada tweet en el cluster\n",
        "kmeans_label = kmeans.labels_[:]\n",
        "label_val = list(kmeans_label)\n",
        "# Adjuntar valores (label) al df\n",
        "df_demo.loc[:,'Label'] = (label_val)\n",
        "df_final = df_demo.iloc[:,[0,4,5,6,7,8,9,10,11]]\n",
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XAiK-nTLB54V"
      },
      "outputs": [],
      "source": [
        "# Localización de los centroides\n",
        "kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEtP16sLIDlE"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jpc9nA07HAEs"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "reduc_val = pca.fit_transform(scaled_val)\n",
        "reduc_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9PBVZdseIPqx"
      },
      "outputs": [],
      "source": [
        "pca_reduc_df = pd.DataFrame(data=reduc_val, columns = ['Componente_1', 'Componente_2'])\n",
        "pca_label_df = pd.concat([pca_reduc_df, df_demo[['Label']]], axis=1)\n",
        "\n",
        "pca_label_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BnxCsJMEOtfM"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (6,6))\n",
        "\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.set_xlabel('Componente 1', fontsize = 15)\n",
        "ax.set_ylabel('Componente 2', fontsize = 15)\n",
        "ax.set_title('Componentes Principales', fontsize = 20)\n",
        "\n",
        "color_theme = np.array([\"blue\", \"green\", \"orange\"])\n",
        "ax.scatter(x = pca_reduc_df.Componente_1, y = pca_label_df.Componente_2,\n",
        "           c=color_theme[pca_label_df.Label], s=10)\n",
        "#plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='black', s=20)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}